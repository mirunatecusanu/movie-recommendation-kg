{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4894ff0e",
   "metadata": {},
   "source": [
    "### Lesson 4: Constructing a Knowledge Graph from Text Documents\n",
    "\n",
    "- source: https://learn.deeplearning.ai/courses/knowledge-graphs-rag/lesson/gxbl6/constructing-a-knowledge-graph-from-text-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80802a",
   "metadata": {},
   "source": [
    "#### Import packages and set up Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b28fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c3e71",
   "metadata": {},
   "source": [
    "Load global variables from the environment and set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# Note the code below is unique to this course environment, and not a \n",
    "# standard part of Neo4j's integration with OpenAI. Remove if running \n",
    "# in your own environment.\n",
    "OPENAI_ENDPOINT = os.getenv('OPENAI_BASE_URL') + '/embeddings'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a6240",
   "metadata": {},
   "source": [
    "#### Take a look at a Form 10-K json file\n",
    "\n",
    "- Publicly traded companies are required to fill a form 10-K each year with the Securities and Exchange Commision (SEC)\n",
    "- You can search these filings using the SEC's [EDGAR database](https://www.sec.gov/edgar/search/)\n",
    "- For the next few lessons, you'll work with a single 10-K form for a company called [NetApp](https://www.netapp.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaed51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_name = \"./data/form10k/0000950170-23-027948.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_as_object = json.load(open(first_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbc1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(first_file_as_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in first_file_as_object.items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_text = first_file_as_object['item1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a57297",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_text[0:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1de97c",
   "metadata": {},
   "source": [
    "#### Split Form 10-K sections into chunks\n",
    "- Set up text splitter using LangChain\n",
    "- For now, split only the text from the \"item 1\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e436b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_text_chunks = text_splitter.split_text(item1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75564582",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item1_text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f70cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item1_text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca1221",
   "metadata": {},
   "source": [
    "- Set up helper function to chunk all sections of the Form 10-K\n",
    "- You'll limit the number of chunks in each section to 20 to speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_form10k_data_from_file(file):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    file_as_object = json.load(open(file)) # open the json file\n",
    "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
    "        print(f'Processing {item} from {file}') \n",
    "        item_text = file_as_object[item] # grab the text of the item\n",
    "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "        chunk_seq_id = 0\n",
    "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
    "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "            # finally, construct a record with metadata and the chunk text\n",
    "            chunks_with_metadata.append({\n",
    "                'text': chunk, \n",
    "                # metadata from looping...\n",
    "                'f10kItem': item,\n",
    "                'chunkSeqId': chunk_seq_id,\n",
    "                # constructed metadata...\n",
    "                'formId': f'{form_id}', # pulled from the filename\n",
    "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
    "                # metadata from file...\n",
    "                'names': file_as_object['names'],\n",
    "                'cik': file_as_object['cik'],\n",
    "                'cusip6': file_as_object['cusip6'],\n",
    "                'source': file_as_object['source'],\n",
    "            })\n",
    "            chunk_seq_id += 1\n",
    "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_chunks = split_form10k_data_from_file(first_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715811e",
   "metadata": {},
   "source": [
    "#### Create graph nodes using text chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d1da5",
   "metadata": {},
   "source": [
    "Use cypher query to merge the chunks into the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.names = $chunkParam.names,\n",
    "        mergedChunk.formId = $chunkParam.formId, \n",
    "        mergedChunk.cik = $chunkParam.cik, \n",
    "        mergedChunk.cusip6 = $chunkParam.cusip6, \n",
    "        mergedChunk.source = $chunkParam.source, \n",
    "        mergedChunk.f10kItem = $chunkParam.f10kItem, \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c835c4b",
   "metadata": {},
   "source": [
    "- Set up connection to graph instance using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6166ee",
   "metadata": {},
   "source": [
    "- Create a single chunk node for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff385c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(merge_chunk_node_query, \n",
    "        params={'chunkParam':first_file_chunks[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e70b8",
   "metadata": {},
   "source": [
    "- Create a uniqueness constraint (index) to avoid duplicate chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664edca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f77fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a03430",
   "metadata": {},
   "source": [
    "- Loop through and create nodes for all chunks\n",
    "- Should create 23 nodes because you set a limit of 20 chunks in the text splitting function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "for chunk in first_file_chunks:\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
    "    kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "    node_count += 1\n",
    "print(f\"Created {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c74bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN count(n) as nodeCount\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71277f",
   "metadata": {},
   "source": [
    "#### Create a vector index\n",
    "\n",
    "For the chunks, we'll create text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13220974",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "        CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "        FOR (c:Chunk) ON (c.textEmbedding) \n",
    "        OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "        }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a2213",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ff469",
   "metadata": {},
   "source": [
    "#### Calculate embedding vectors for chunks and populate index\n",
    "- This query calculates the embedding vector and stores it as a property called `textEmbedding` on each `Chunk` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba42082",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "    WITH chunk, genai.vector.encode(\n",
    "        chunk.text, \n",
    "        \"OpenAI\", \n",
    "        {\n",
    "        token: $openAiApiKey, \n",
    "        endpoint: $openAiEndpoint\n",
    "        }) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "    \"\"\", \n",
    "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64612ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aba60",
   "metadata": {},
   "source": [
    "Now that we have a knowledge graph, we can create a helper function for vector search using neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ceef95",
   "metadata": {},
   "source": [
    "#### Use similarity search to find relevant chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c715cdb",
   "metadata": {},
   "source": [
    "- Setup a help function to perform similarity search using the vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "    \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "    vector_search_query = \"\"\"\n",
    "        WITH genai.vector.encode(\n",
    "            $question, \n",
    "            \"OpenAI\", \n",
    "            {\n",
    "            token: $openAiApiKey,\n",
    "            endpoint: $openAiEndpoint\n",
    "            }) AS question_embedding\n",
    "        CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "        RETURN score, node.text AS text\n",
    "        \"\"\"\n",
    "similar = kg.query(vector_search_query, \n",
    "                    params={\n",
    "                    'question': question, \n",
    "                    'openAiApiKey':OPENAI_API_KEY,\n",
    "                    'openAiEndpoint': OPENAI_ENDPOINT,\n",
    "                    'index_name':VECTOR_INDEX_NAME, \n",
    "                    'top_k': 10})\n",
    "return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c9b65",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ffc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'In a single sentence, tell me about Netapp.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730aceef",
   "metadata": {},
   "source": [
    "The helper function returns a list of results, here we look at result 0 and see a score of how similar this text was and the text with what we asked for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd72833",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8315870",
   "metadata": {},
   "source": [
    "Note that we only created vector search. If we wanted to create a chatbot that provides answers to a question, we can build a RAG system using Langchain.\n",
    "\n",
    "The easiest way to do this - neo4j vector interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d09477",
   "metadata": {},
   "source": [
    "#### Set up a LangChain RAG workflow to chat with the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229f899",
   "metadata": {},
   "source": [
    "Under the hood, this will use cypher language to perform vector similarity searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e830c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = neo4j_vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2551b65f",
   "metadata": {},
   "source": [
    "- Set up a RetrievalQAWithSourcesChain to carry out question answering\n",
    "- You can check out the LangChain documentation for this chain [here](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce067c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f5232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
    "    response = chain({\"question\": question},\n",
    "        return_only_outputs=True,)\n",
    "    print(textwrap.fill(response['answer'], 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156962d1",
   "metadata": {},
   "source": [
    "- Ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd713738",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Netapp's primary business?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895796ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(\"Where is Netapp headquartered?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe64a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Netapp. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6a836",
   "metadata": {},
   "source": [
    "Example: classic hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdbee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa24354",
   "metadata": {},
   "source": [
    "Trying to fix hallucination with a bit of prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "prettychain(\"\"\"\n",
    "    Tell me about Apple. \n",
    "    Limit your answer to a single sentence.\n",
    "    If you are unsure about the answer, say you don't know.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b93ade",
   "metadata": {},
   "source": [
    "#### Ask you own question!\n",
    "- Add your own question to the call to prettychain below to find out more about NetApp\n",
    "- Here is NetApp's website if you want some inspiration: https://www.netapp.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb49661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
